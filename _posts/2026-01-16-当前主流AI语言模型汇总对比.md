---
layout: post
toc: true
title: "当前主流 AI 语言模型深入汇总对比"
categories: LLM
tags: [LLM, NLP]
author:
  - vortezwohl
  - 吴子豪
---
## Google 系, 包括 DeepMind, Google Research, Google Brain(前) 等团队

模型名|特点|参数规模|核心特性|开源情况|商用价格(Per 1M Tokens)|备注
:--:|:--:|:--:|:--:|:--:|:--:|:--:
**Gemini-3-Pro**|旗舰级 多模态|7500B(150B激活) (估计)|100 万 token 上下文，文本 + 图像 + 音频 + 视频全模态，意图洞察架构|闭源|输入:$2<br>输出:$12|思维链输出特别长, 用于简单任务用力过猛, 仅适用于复杂任务或 Agentic 任务
**Gemini-3-Flash**|轻量级 高性能|1200B(36B激活) (估计)|100 万 token 上下文，3 倍速度提升，免费覆盖多渠道|闭源|输入:$0.5<br>输出:$3|性能与 Gemini-2.5-Pro 齐平, 但单价更低
**Gemini-2.5-Pro**|通用性最佳|1800B(36B激活) (估计)|100 万→200 万 token 上下文，思维链机制，多模态编程能力|闭源|输入:$1.25<br>输出:$10|适用于所有任务, 但单价偏高
**Gemini-2.5-Flash**|轻量级 更快速|46B (估计)|100 万 token 上下文，可调思考预算（0-24576 tokens）|闭源|输入:$0.3<br>输出:$2.5|适用于大多数任务, 平衡速度与性能, 单价币 Pro 规模更低
**Gemini-2.5-Flash-Lite**|轻量级 更廉价|20B (估计)|100 万 token 上下文，比 Flash 便宜 30%-60%|闭源|输入:$0.1<br>输出:$0.4|适用于简单任务, 速度快, 单价低
**Gemma-3-27B/12B/4B/1B/270M**|开源|27B/12B/4B/1B/270M|多模态（文本 + 图像），128K token 上下文，5:1 局部 / 全局层交错注意力|开源, [获取权重](https://huggingface.co/collections/google/gemma-3-release)|/|Apache 2.0 协议免费商用, 消费级 GPU 可部署
**Gemma-3n-E4B/E2B**|MatFormer 弹性推理架构创新 内存占用小 可端侧部署|8B(4B激活)/5B(2B激活)|引入PLE 技术，专为 Android 设备优化，4 位量化部署，本地离线推理|开源, [获取权重](https://huggingface.co/collections/google/gemma-3n)|/|弹性调节推理质量与延迟, 端侧设备 (Pixel 手机) 可部署

## OpenAI 系

模型名|特点|参数规模|核心特性|开源情况|商用价格(Per 1M Tokens)|备注
:--: | :--: | :--: | :--: | :--: | :--: | :--:
| **GPT-5.2-Instant**  | 极速响应，低延迟 | 70B (估计) | 响应速度比 GPT-5.1 提升 40%，延迟稳定在 500ms 以内；专为日常轻量级任务设计；支持 16K-128K 上下文窗口         | 闭源              | 输入:$1.75<br>输出:$14              | 免费用户默认版本，付费用户可升级上下文窗口      |
| **GPT-5.2-Thinking** | 深度推理，专业级 | 400B (估计) | GDPval 评测 70.9% 任务达到或超过人类专家水平；SWE-bench Verified 测试 80% 准确率；支持 196K 上下文窗口 | 闭源              | 输入:$1.75<br>输出:$14              | 付费用户专享，适合复杂推理任务            |
| **GPT-5.2-Pro**      | 极致精度，企业级 | 540B (估计) | 最高推理精度，支持 xhigh 级推理强度；GDPval 评测 74.1% 任务达到或超过人类专家水平；支持 400K 上下文窗口         | 闭源              | 输入:$21.00<br>输出:$168.00                               | 最高端版本，仅对 Pro/Business 用户开放 |
| **GPT-5.2-Codex**    | 智能体编程    | 400B (估计) | 支持异步自主编程，可独立运行 7 + 小时；上下文压缩技术；支持 128K 代码生成长度；智能体工作流优化                     | 闭源              | 输入:$1.75<br>输出:$14              | 专为编程任务优化，ChatGPT Plus 用户免费 |
| **GPT-OSS-120b**     | 开源旗舰，高性能 | 116.8B | 36 层 MoE 架构，每 token 激活 51 亿参数；性能接近 o4-mini；支持 128K 上下文；需 80GB 内存          | 开源, [获取权重](https://huggingface.co/openai/gpt-oss-120b) | / | 官方开源，可免费商用                 |
| **GPT-OSS-20b**      | 轻量开源，便携  | 20.9B  | 24 层 MoE 架构，每 token 激活 36 亿参数；仅需 16GB 内存即可运行；性能接近 o3-mini                 | 开源, [获取权重](https://huggingface.co/openai/gpt-oss-20b) | / | 适合边缘设备部署，开发测试免费            |

> 2025 年 11 月 GPT-5.1 发布后，GPT-5 作为旧版模型保留 90 天；2026 年 1 月 GPT-5.2 上线后，该保留期同步延续，仅对付费用户开放。保留期结束后，GPT-5 将完全下线，无法通过任何渠道访问，GPT-5.1 虽暂不停用，但 OpenAI 已停止功能更新，仅维持稳定性维护，长期建议逐步迁移至 GPT-5.2 系列。

- **最新进展**

    GPT-5 系列模型（5.0/5.1/5.2）是 OpenAI 在 2025 年推出的新一代大型语言模型系统，核心突破集中在统一智能架构、深度推理能力、长上下文理解、多模态融合和代理式工具调用五个方向，通过持续迭代实现了从 "文本生成器" 到 "通用智能体".

    1. **GPT-5 / 5.1 的创新点**

        - **核心架构创新**

            GPT-5 摒弃了前代单一模型设计，采用三位一体的统一系统架构$^{[1]}$，由三个核心组件构成:

            - **高效基础模型**: 处理简单问题, 响应快, 成本低.

            - **深度推理模型**: 解决 STEM 复杂任务, 通过内部思维链生成更可靠答案.

            - **实时路由机制**: 基于对话类型, 复杂度, 工具需求甚至用户明确意图(例如在提示词中写"请你深入思考")等, 自动选择最优模型进行处理. 路由系统还会通过持续学习用户行为信号（如模型切换、回复偏好）不断优化决策，实现 "每次都给出最佳响应" 的目标$^{[1]}$.

        - **推理能力增强**

            GPT-5 引入深度推理训练机制，通过强化学习让模型学会 "思考后再回答"，能够产生长内部思维链，尝试不同策略并识别错误。关键创新包括：

            - **推理粒度控制**: API 提供 none/low/medium/high 四档推理强度，开发者可精确控制模型思考深度$^{[1]}$.

            - **递归问题求解**: 自动将复杂任务拆解为子任务，通过多轮推理验证答案一致性$^{[1]}$.

            - **反事实推理**: 在数学和科学领域表现突出，首次通过哥德尔测试并解决三个组合优化领域的数学猜想$^{[1]}$.

        - **幻觉减少与安全性增强**

            - **幻觉减少**: 基础模型幻觉率较 GPT-4o 下降 45%（9.6%→12.9%），thinking 模型降至 4.5%，在 LongFact 和 FActScore 测试中减少约 60%.

            - **减少谄媚**: 通过新评估方法和针对性训练，解决 GPT-4o 曾出现的过度迎合问题.

    2. **GPT-5.2 的创新点**

        GPT-5.2 正式确立三级智能体体系 (Instant, Thinking, Pro 三级体系)$^{[2]}$，突破 GPT-5/5.1 的双模型架构，实现效率与能力的精确匹配. 除此之外, GPT-5.2 还引入了推理加速技术和若干关键创新.

        - **推理加速: 动态计算图生成**

            GPT-5.2 引入动态计算图生成技术，实现 "思考深度" 与计算资源的精准映射：

            ```
            Input → Task Analyzer → Compute Graph Generator → Resource Allocator → Model Execution
            ```

            该算法由 3 个核心组件构成:

            1. 任务分析器: 通过 128 维任务向量表征，预测所需推理步数、注意力头数、专家数量.

            2. 计算图生成器: 动态构建包含 "子任务分解→推理验证→结果整合" 的计算流程.

            3. 资源分配器: 基于任务向量与系统负载，实时调整 GPU/TPU 计算资源分配.

            > 在 AIME 2025 数学竞赛中，动态计算图使 Thinking 模型在保持 92.1% 准确率的同时，推理时间减少 38%

        - **长上下文理解增强: HHSA 混合层级稀疏注意力**

            GPT-5.2 Thinking 版本实现256k token 上下文窗口的高质量理解，核心在于 Hybrid Hierarchical Sparse Attention (HHSA) 机制:

            1. **分层注意力架构**

                - 局部注意力 (Local Attention): 窗口大小 2048 tokens, 处理相邻的上下文依赖.

                - 全局稀疏注意力 (Global Sparse Attention): 采用"重要性采样"策略, 仅关注文档中 5% 的关键 tokens.

                - 文档级注意力 (Document-level Attention): 基于文档结构(章节, 段落等)的粗粒度注意力, 意在建立长距语义关联.

            2. **稀疏激活优化**

                - 动态稀疏度调整: 根据上下文内容复杂度, 自动调整全局注意力的稀疏比例 (3% 到 10%)

                - 缓存感知注意力: 对高频引用的上下文片段建立专用缓存, 大幅提升访问速度.

                - 渐进式上下文加载: 长文档处理时采用"先摘要 -> 再细节"的加载策略, 内存占用减少 65%.

            > GPT-5.2 首次在 256k token 长度下实现 "非均匀信息分布"的精准理解，解决了长上下文处理中" 信息稀释 " 的核心难题

        - **视频理解能力的首次实现**

            GPT-5.2 首次实现完整视频理解能力，超越帧级分析，达到视频语义理解级别. 其主要依赖以下核心技术:

            - **时空注意力**: 同时捕捉视频的空间特征 (帧内) 与时间特征 (帧间).

            - **视频摘要生成**: 基于关键帧提取与语义压缩，生成准确率达 89.1% 的视频内容摘要.

            - **场景转换检测**: 自动识别视频中的场景切换，支持段落式视频内容描述.

            > 在 MSVD 视频描述基准上，BLEU-4 分数从 GPT-5.1 的 62.3 提升至 78.5，METEOR 分数从 68.1 提升至 82.7.

## Anthropic 系

模型名|特点|参数规模|核心特性|开源情况|商用价格(1M/Tokens)|备注
:--: | :--: | :--: | :--: | :--: | :--: | :--:
|**Claude Opus 4.5**|旗舰级 智能体编程|未知|200K默认上下文（100万token向特定客户开放），多模态（文本+图像+表格），SWE-bench Multilingual领先，支持effort参数调节，多智能体协作，对齐安全性行业顶尖|闭源|输入:$5<br>输出:$25|定价较上代降2/3，适合复杂编程、深度研究，Team/Enterprise用户可Excel内嵌使用|
|**Claude Sonnet 4.5**|中高端 平衡型|未知|200K上下文窗口，平衡性能与成本，中等effort下与上代Opus精度持平且token用量减76%，支持多工具协同与长程任务稳定运行|闭源|输入:$2<br>输出:$10|企业大规模部署优选，兼顾效率与成本，适配桌面端多会话并行|
|**Claude Haiku 3**|轻量级 极速响应|未知|200K上下文窗口，近实时响应（延迟＜300ms），支持基础多模态解析，低资源消耗，适合高频简单任务|闭源|输入:$0.4<br>输出:$2|替代旧版Haiku，性价比优于同类轻量模型，适合实时客服、快速问答场景|

> Claude 3系列（Opus/Sonnet/Haiku）已进入维护期，停止功能更新，仅保障稳定性；2025年11月Opus 4.5发布后，旧版Claude 3模型保留60天访问权，仅限付费用户手动切换，到期后将逐步下线，建议迁移至4.5系列及Haiku 3。


## 参考文献

[[1](https://doi.org/10.48550/arXiv.2601.03267)] Aaditya Singh et al. OpenAI GPT-5 System Card. *arXiv preprint*, 2025.

[[2](https://openai.com/index/introducing-gpt-5-2/)] OpenAI Research Team. Introducing GPT-5.2. *OpenAI Official Website*, 2025.