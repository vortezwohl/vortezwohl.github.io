---
layout: post
toc: true
title: "Agent 长期记忆策略调研: MemoryOS, 首个智能体记忆系统"
categories: LLM
tags: [NLP, LLM]
author:
  - vortezwohl
  - 吴子豪
---

MemoryOS 作为首个为 AI 智能体设计的记忆操作系统，成功将现代操作系统的段页式内存管理原理与 LLM 智能体的对话场景结合，构建了三级分层存储 + 四大核心模块的一体化记忆管理框架，有效突破了 LLMs 固定上下文窗口的核心缺陷，实现了长对话的上下文连贯性和个性化交互，在 GVD、LoCoMo 数据集上的性能显著优于现有 SOTA 方法。该研究的核心价值不仅在于提出了一种新的记忆管理技术，更在于为 LLM 智能体的记忆管理研究提供了全新的思路—— 将传统工程领域的成熟管理原理与 AI 场景结合，实现跨领域的技术创新。同时，MemoryOS 的开源代码也为行业提供了可复用的工程方案，推动了 AI 智能体在真实交互场景的落地。但是，MemoryOS 目前仍存在超参数敏感、硬件门槛高、场景适配性不足等局限性，但后续通过超参数自适应、轻量化设计、多模态拓展等优化，其在智能助手、在线客服、多智能体协作等场景的应用价值将进一步提升。

Paper: [Memory OS of AI Agent](https://doi.org/10.48550/arXiv.2506.06326)

## 业界难题

当前大语言模型在 AI 智能体交互场景中，核心瓶颈集中在固定上下文窗口和记忆管理体系缺失，导致长期记忆能力严重不足，具体问题可分为技术层面和机制层面两大维度：

1. **技术层面: 固定上下文窗口的固有缺陷**

    - LLMs 依赖固定长度的上下文窗口进行记忆管理，无法维持长时距对话的连续性，易出现事实不一致、对话逻辑断裂的问题；

    - 对多会话知识保留、持续用户偏好适配、智能体稳定角色表征等场景的支持能力极差，成为 AI 智能体落地真实交互场景的核心障碍；

    - 原始记忆管理方式仅能存储原始对话数据，缺乏对对话内容的结构化、分层化组织，导致记忆利用率低、检索效率差。

2. **机制层面: 现有记忆管理方法的孤立性**

    现有 LLMs 记忆机制虽有三类技术路线，但均聚焦单一维度优化（存储结构 / 检索机制 / 更新策略），缺乏系统化、一体化的记忆管理框架：

    - 部分方法仅关注存储结构设计，忽略动态更新与高效检索的协同；

    - 部分方法优化检索机制，但未结合用户 / 智能体的人格持久化需求；

    - 部分方法改进架构层面的记忆控制，但存在话题混合、延迟过高、错误累积等衍生问题；

    - 无统一的 “操作系统级” 框架实现记忆的存储、更新、检索、生成全流程协同管理。

## 相关工作研究进展

该研究的相关工作分为 LLM 智能体的记忆管理研究和操作系统的内存管理原理两大板块，其中前者是研究的直接背景，后者是 MemoryOS 的核心灵感来源。

1. LLM 智能体的记忆管理研究

    现有研究路线主要分为知识组织、检索机制、架构驱动三类, 各路线的核心思路, 代表方法和特点如下表:

    |研究路线|核心思路|代表方法|优点|局限性|
    |:-:|:-:|:-:|:-:|:-:|
    知识组织|捕捉 LLM 推理状态, 将知识结构化存储为语义网络/推理链/笔记|TiM, A-Mem $^{[1]}$, Grounded Memory|减少推理冗余，实现跨会话知识关联|未考虑高效检索与动态更新的协同，部分方法链路生成耗时高
    检索机制|构建外部记忆库，结合遗忘曲线 / 情感状态 / 语义相似度实现记忆检索与更新|MemoryBank $^{[5]}$、AI-town $^{[2]}$、EmotionalRAG $^{[3]}$|适配长时记忆的遗忘特性，支持情感化检索|仅优化检索，缺乏系统化存储架构，记忆管理效率低
    架构驱动|改造 LLM 核心控制流，设计显式的读写操作和分层记忆结构|MemGPT $^{[4]}$、SCM $^{[6]}$|突破固定上下文窗口限制，支持记忆扩展|MemGPT 易出现话题混合$^{[4]}$，SCM 的缓存控制逻辑复杂$^{[6]}$

    以上三类方法均未解决**记忆管理全流程的协同问题**，于是 MemoryOS 以此作为核心研究切入点。

2. 操作系统的内存管理原理

    现代操作系统的内存管理技术是 MemoryOS 的设计基石，核心借鉴点包括：

    1. **段页式混合管理**: 将内存分为粗粒度的**段**（逻辑主题）和细粒度的**页**（数据单元），平衡逻辑结构与物理利用率，解决内 / 外部碎片问题；
    
    2. **基于优先级的淘汰策略**: 采用 LRU、工作集模型等保留**热数据**，高效丢弃 / 归档低访问度数据；

    3. **粗粒度分段 + 细粒度分页**: 在多核心处理器中可最小化管理开销，为对话内容的分层存储提供了技术参考。

    MemoryOS 将上述 OS 内存管理原理与 LLM 智能体的对话场景结合，实现了 “段 - 页” 结构在对话记忆中的适配与创新。

## MemoryOS 方法论

MemoryOS 是首个为 AI 智能体设计的系统化记忆操作系统，核心设计思路为：借鉴 OS 段页式内存管理原理，构建三级分层存储架构 + 四大核心功能模块，实现记忆的分层存储、动态更新、自适应检索和上下文生成的全流程协同:

- **整体架构: 四大核心功能模块**

    MemoryOS 由**记忆存储（Storage）**、**记忆更新（Update）**、**记忆检索（Retrieval）**、**响应生成（Generation）**四大模块组成，各模块协同工作，形成统一的记忆管理框架，模块间的核心流转逻辑为：用户查询触发三级内存检索→检索结果融合为 LLM 提示词→生成上下文连贯且个性化的响应→对话数据反向更新三级记忆。

- **核心模块**

    - **记忆存储, 三级分层存储架构**

        突破现有方法的扁平存储模式，设计短时记忆（STM）、中期记忆（MTM）、长期人格记忆（LPM） 三级分层存储，各层级的存储内容、数据结构、设计目标高度适配对话场景的内存需求，具体设计如下：

        1. **短时记忆（STM）**: 

            - 存储内容: 实时对话数据，以对话页为基本单元，包含用户查询、模型响应、时间戳及链元信息；

            - 数据结构: 固定长度的对话页队列, 构建对话链维持短期对话的上下文连贯性;

            - 设计目标: 保障当前会话的实时上下文一致性;

        2. **中期记忆（MTM）**:

            - 核心创新: 引入**段页式存储架构**，将相同话题的对话页归为一个段，段内包含多个对话页；

            - 话题匹配: 通过 F_score（语义相似度 + 杰卡德关键词相似度）判断对话页与段的相关性，超过阈值则合并；

            - 设计目标: 实现对话内容的按话题结构化存储，解决话题混合问题。

        3. **长期人格记忆（LPM）**:

            - 组成部分: 分为**用户人格**和 **AI 智能体人格**，均包含静态属性（姓名、角色设定等）和动态属性（用户兴趣、交互历史等）；

            - 核心设计: 用户人格包含 90 维特征（基础需求 / AI 对齐 / 内容平台兴趣），动态提取自对话内容，实现人格的演化；

            - 设计目标: 保障长时交互中用户 / 智能体人格的持久化与动态更新，提升个性化。

    - **记忆更新, 热度驱动 + FIFO 动态流转**

        设计跨层级的内存动态更新策略，实现 STM → MTM → LPM 的有序数据流转，核心依赖 FIFO（先进先出）和热度评分（Heat）两大机制，解决内存的容量控制和热数据保留问题：

        1. **STM → MTM**: 采用 FIFO 策略，当 STM 队列达到最大容量时，最旧的对话页被转移至 MTM 对应话题段；

        2. **MTM 内部更新**: 基于 Heat 评分实现段的淘汰，Heat 评分由**检索次数、交互页数、时间衰减系数**加权计算，低分段被优先淘汰；

        3. **MTM → LPM**: Heat 评分超过阈值的段被转移至 LPM，更新用户 / 智能体的动态属性，且段的交互页数重置，避免记忆冗余；

        4. **LPM 自身更新**: 用户知识库 / 智能体特征采用 FIFO 队列，固定容量，实现动态属性的增量更新。

    - **记忆检索, 三级差异化的自适应检索策略**

        针对 STM、MTM、LPM 的存储特性设计差异化检索策略，确保检索的精准性和效率，核心逻辑为：

        1. **STM 检索**: 全量检索, 因为存储的是当前会话的最新上下文, 是响应生成的基础.

        2. **MTM 检索**: 采用**两阶段检索** (段 → 页), 先通过 F_score 选 Top-M 相关段, 再在段内选择 Top-K 相关对话页, 检索后更新段的 Heat 评分.

        3. **LPM 检索**: 语义匹配选 Top-10 相关条目, 同时全量利用用户 / 智能体的静态 + 动态属性, 为个性化响应提供支撑.

    - **响应生成, 三级记忆信息的融合 Prompt**

        将 STM 的实时上下文、MTM 的历史话题内容、LPM 的人格属性融合为统一的提示词，输入 LLM 生成最终响应，确保响应同时满足**上下文连贯性、历史关联性、个性化**三大要求。

- **创新点**

    1. **首创性**: 提出首个为 AI 智能体设计的系统化记忆操作系统，打破现有记忆机制的孤立性，实现存储、更新、检索、生成的全流程协同；

    2. **架构创新**: 构建三级分层存储 + 段页式 MTM 设计，将 OS 内存管理原理成功适配到 LLM 对话场景，解决固定上下文窗口的核心缺陷；

    3. **机制创新**: 设计**热度驱动的跨层级记忆更新策略**，实现热数据的精准保留和记忆的高效容量控制；

    4. **人格融合**: 引入 LPM 长期人格记忆模块，实现用户/智能体人格的持久化与动态演化，提升长时交互的个性化；

## MemoryOS 解决的问题

1. **解决 MemGPT 的话题混合问题$^{[4]}$**：通过 MTM 的段页式设计，将对话内容按话题结构化存储，避免不同话题的内容混杂；

2. **解决 A-Mem 的高延迟 / 错误累积问题$^{[1]}$**：简化语义网络的构建逻辑，减少 LLM 调用次数（A-Mem * 为 13 次，MemoryOS 为 4.9 次），降低链路生成的错误率；

3. **解决 MemoryBank 的管理效率低问题$^{[5]}$**：通过 Heat 评分实现热数据的智能保留，避免单纯依赖遗忘曲线导致的有效信息丢失。

在效率上, MemoryOS 也显著优于现有 SOTA 方法:

1. 相比 MemGPT，token 消耗减少 77.2%（3874 vs 16977 $^{[4]}$），解决了大内存检索的高 token 开销问题；

2. 相比 A-Mem*，LLM 平均调用次数减少 62.3%（4.9 vs 13 $^{[1]}$），降低了推理延迟；

3. 在 GVD 数据集上，MemoryOS 的检索准确率、响应正确性、上下文连贯性均为最优，实现性能与效率的双重提升。

## MemoryOS 的局限性

该研究在实验验证和技术设计上取得了显著成果，但从**工程化落地**角度，仍存在以下局限性，且论文未对相关问题进行深入探讨：

1. **超参数敏感, 调优成本高**

    MemoryOS 的核心性能依赖多个超参数（如 MTM 检索的 Top-K、话题匹配阈值 $\theta$、Heat 评分阈值 $\tau$、加权系数 $\alpha/\beta/\gamma$ 等），且这些超参数针对不同数据集需单独调优（如 LoCoMo 设 $K=10$，GVD 设 $K=5$），缺乏自适应调节能力，增加了跨场景的部署调优成本。

2. **数据集验证范围的局限性**

    实验仅在 GVD（多轮模拟对话）和LoCoMo（超长长对话）两个文本对话数据集上验证，未在多模态交互（视觉 / 语音）、实时交互（如直播、在线客服）、多智能体协作等复杂场景中验证，模型的泛化性待进一步检验。

3. **人格特征的固定维度设计缺乏灵活性**

    LPM 模块的用户人格采用固定 90 维特征，未考虑不同领域 / 用户群体的特征差异（如儿童智能助手、企业客服的用户特征需求不同），固定维度设计会导致部分场景下的特征冗余或缺失，影响个性化效果。

4. **记忆压缩与容错机制缺失**

    MemoryOS 未设计记忆压缩技术，对于超大规模的对话数据，仍会存在 token 消耗过高的问题；同时缺乏容错机制，当对话页 / 段的匹配出现错误时，会直接影响检索和响应生成的准确性，鲁棒性待提升。

## 参考文献

[[1](https://doi.org/10.48550/arXiv.2502.12110)] Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang. A-MEM: Agentic Memory for LLM Agents. *arXiv preprint*, 2025.

[[2](https://doi.org/10.48550/arXiv.2304.03442)] Joon Sung Park, Joseph C. O'Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, Michael S. Bernstein. Generative Agents: Interactive Simulacra of Human Behavior. *arXiv preprint*, 2023.

[[3](https://doi.org/10.48550/arXiv.2410.23041)] Le Huang, Hengzhi Lan, Zijun Sun, Chuan Shi, Ting Bai. Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval. *arXiv preprint*, 2024.

[[4](https://doi.org/10.48550/arXiv.2310.08560)] Charles Packer, Sarah Wooders, Kevin Lin, Vivian Fang, Shishir G. Patil, Ion Stoica, Joseph E. Gonzalez. MemGPT: Towards LLMs as Operating Systems. *arXiv preprint*, 2023.

[[5](https://doi.org/10.48550/arXiv.2305.10250)] Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, Yanlin Wang. MemoryBank: Enhancing Large Language Models with Long-Term Memory. *arXiv preprint*, 2023.

[[6](https://doi.org/10.48550/arXiv.2304.13343)] Bing Wang, Xinnian Liang, Jian Yang, Hui Huang, Shuangzhi Wu, Peihao Wu, Lu Lu, Zejun Ma, Zhoujun Li. SCM: Enhancing Large Language Model with Self-Controlled Memory Framework. *arXiv preprint*, 2023.
