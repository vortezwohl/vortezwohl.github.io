---
layout: post
toc: true
title: "Branch-Solve-Merge: 用并行的分治方法提高 LLM 生成质量"
categories: LLM
tags: [NLP, LLM]
author:
  - vortezwohl
  - 吴子豪
---

在大语言模型（LLMs）广泛应用于文本生成与评估任务的背景下，复杂多维度需求（如满足多重约束、兼顾多元评价标准）成为业界面临的核心挑战。现有 LLMs 常因缺乏自洽性、规划能力不足和任务分解能力薄弱，导致在长文本评估、约束性生成等场景中表现不佳，同时存在位置偏差、长度偏差等问题，且人工设计评估方案扩展性差、GPT-4 等优质评估模型成本高昂。相关研究围绕 LLM 程序设计、任务分解、评估优化和约束生成展开，形成了迭代推理、规划提示、多智能体辩论等技术路径，但现有方法多聚焦于序列式分解的推理任务，对并行分解的适配性不足，且在兼顾评估准确性与生成连贯性上仍有提升空间。BSM 作为一种通用的 LLM 程序框架，通过分支 - 求解 - 合并的模块化设计，为解决上述问题提供了创新方案，显著提升了多维度任务的处理效果。

Paper: [Branch-Solve-Merge Improves Large Language Model Evaluation and Generation](https://doi.org/10.48550/arXiv.2310.15123)

## 业界难题

1. **多维度任务适配难**：LLM 需处理复杂且多元的需求，如评估任务中需兼顾不同领域的专属标准（编码任务关注代码正确性，写作任务关注原创性），生成任务中需平衡约束满足与连贯性。

2. **评估可靠性不足**：LLM 作为评估者时存在位置偏差（受响应展示顺序影响）、长度偏差（偏好更长响应）、自我增强偏差（偏好自身生成的响应），且人工设计评估方案无法适配所有领域，扩展性差。

3. **生成质量与约束冲突**：约束文本生成中，LLM 易出现概念遗漏或为满足约束导致文本逻辑混乱的问题，即使 GPT-4 等先进模型也难以兼顾二者。

4. **成本与性能平衡**：GPT-4 等优质模型作为评估者效果较好，但存在 API 调用成本高的问题；开源模型则存在与人类判断一致性低、偏差更显著的缺陷。

## 相关工作

1. **LLM 程序与复杂任务分解**：相关研究通过将复杂任务分解为多步骤，并用不同提示词参数化 LLM 实现分步处理，如 Graph-of-Thoughts（GoT）提示法将任务执行轨迹建模为图结构，支持优化、回溯等操作。但现有方法多聚焦于序列式分解的推理任务（如常识推理、数学计算），对并行分解的适配性不足，且未针对评估和约束生成等场景设计专用框架。

2. **LLM 评估优化**：现有评估方案主要包括：
    
    1. 利用 GPT-4 等强 LLM 作为评估者，依赖其与人类的对齐性；
    
    2. 多智能体辩论法提升评估客观性；
    
    3. 通过扩大模型规模改善评估公平性。但这些方法未从任务分解角度解决偏差问题，且存在成本高、扩展性差的缺陷，无法适配多领域多维度评估需求。

3. **约束文本生成**：现有研究通过谓词逻辑约束解码、神经启发式搜索等方法提升生成的可控性，但即使先进模型仍面临约束遗漏与连贯性冲突的问题，缺乏有效的任务分解与融合机制来平衡二者。

## 方法论

1. **核心创新点**

    1. **通用模块化框架**：BSM 以 LLM 程序为核心，设计分支（branch）、求解（solve）、合并（merge）三大模块化组件，通过专用提示词参数化，可适配 LLM 评估和约束生成等不同任务，无需修改模型结构。

    2. **并行化任务分解**：不同于传统序列式分解，BSM 通过分支模块将原任务分解为多个并行子任务（如评估任务分解为不同维度的评价标准，生成任务分解为不同概念子集的故事片段创作），每个子任务独立求解后再融合，提升处理效率与针对性。

    3. **自适应评估方案生成**：分支模块可根据任务领域自动生成专属评估标准（如编码任务生成 “代码可读性”“正确性” 等标准，写作任务生成 “原创性”“相关性” 等标准），解决人工设计方案扩展性差的问题。

    4. **偏差缓解机制**：通过求解模块中响应顺序交换、合并模块中多维度分数聚合，有效降低位置偏差、长度偏差等，提升评估可靠性。

2. **解决的核心问题**

    1. **多维度任务适配**：通过并行分解与自适应子任务生成，使 LLM 可针对性处理不同领域、不同维度的需求，提升任务处理的精准度。

    2. **评估偏差与可靠性**：显著降低位置、长度、自我增强等偏差，提升 LLM 评估与人类判断的一致性，同时降低对 GPT-4 等高价模型的依赖。

    3. **生成质量与约束平衡**：通过子任务分解降低单个生成步骤的约束复杂度，再通过合并模块保证整体连贯性，提升约束满足率与文本质量。

    4. **扩展性与通用性**：框架不依赖特定 LLM，可适配开源模型（如 LLaMA-2、Vicuna）与闭源模型（如 GPT-4），且可扩展至更多自然语言处理任务。

## 技术原理与实现

1. **核心定义**

    BSM 的核心是通过三大模块的协同工作实现复杂任务处理，设基础 LLM 为 $p_{\theta}$，输入任务为 $x$，输出结果为 $y$，整体流程为：$x \xrightarrow{branch} \{x^{(1)},x^{(2)},...,x^{(k)}\} \xrightarrow{solve} \{y^{(1)},y^{(2)},...,y^{(k)}\} \xrightarrow{merge} y$，其中 $k$ 为分支因子（子任务数量）。

2. **模块详细实现**

    1. **分支模块**

        - **功能**：将原任务分解为多个并行子任务，子任务类型由任务场景决定。

        - **评估任务**：输入用户问题（单轮或多轮），生成评估标准集合（含标准名称与描述），如写作任务生成 “原创性”“相关性” 等标准，编码任务生成 “代码正确性”“效率” 等标准，分支因子最大为 5。

        - **生成任务**：输入概念集合，生成故事主题与两个概念子集，确保无概念遗漏，且子集对应的故事片段可融合为完整文本。

    2. **求解模块**

        - **功能**：独立处理每个子任务，生成子结果。

        - **评估任务**：输入问题、两个 LLM 响应与单个评估标准，输出两个响应的分数（1-5 分）与解释，为缓解位置偏差，支持交换响应顺序进行两次求解。

        - **生成任务**：输入概念子集与故事主题，生成包含该子集所有概念的连贯故事片段。

    3. **合并模块**

        - **功能**：融合子结果为最终答案，兼顾准确性与连贯性。

        - **评估任务**：采用非神经融合（分数求和）或神经融合（LLM 生成最终 verdict），输出 “A 更优”“B 更优” 或 “平局”，仅当两次顺序交换后的求解结果一致时才判定某方更优，否则为平局。

        - **生成任务**：输入两个故事片段与对应概念子集，融合为包含所有概念的连贯故事，确保无概念遗漏。

3. **关键细节**

    - **提示词设计**：每个模块采用专用提示词，明确任务目标与输出格式，如分支提示词指定评估标准数量与描述要求，求解提示词限制仅基于指定标准评分。

    - **解码策略**：所有模块采用贪心解码，保证结果稳定性。

    - **偏差处理**：评估任务中通过两次顺序交换求解、合并时一致性校验，降低位置偏差；分支分解使长度仅作为单一评估维度，降低长度偏差影响。

## 实验验证

1. **实验设置**

    - **数据集**

        - 评估任务：采用 MT-Bench 数据集，含 8 个领域（写作、编码、推理、数学等）的多轮对话响应，共 2400 个 LLM 响应与 3000 个人类判断。

        - 生成任务：基于 CommonGen 数据集扩展，含 100 个样本，每个样本需融入 10 个概念生成故事。

    - **模型与基线方法**

        - 测试模型：开源模型（LLaMA-2-7B-chat、LLaMA-2-70B-chat、Vicuna-33B）与闭源模型（GPT-4）。

        - 基线方法：零样本提示（相对评估 / 绝对评估）、Plan&Solve（仅规划不并行求解）、自我一致性（多次采样后多数投票）。

    - **评估指标**

        - 评估任务：LLM - 人类一致性（Ag）、位置偏差（PB）、长度偏差（LB）、自我增强偏差（SB）。

        - 生成任务：约束满足率（AP：所有概念存在的样本比例；MC：平均缺失概念比例）、故事质量（GPT-4 pairwise 评估偏好率）。

2. **核心实验结果**

    - **评估任务**

        1. 一致性提升：LLaMA-2-70B-chat+BSM 在写作领域的人类一致性达 0.55，较零样本相对评估（0.43）提升 12%，较自我一致性（0.52）提升 3%；GPT-4+BSM 较纯 GPT-4 提升 3%，LLaMA-2-70B-chat+BSM 在多个领域（如数学）表现优于 GPT-4。

        2. 偏差缓解：LLaMA-2-70B-chat+BSM 的位置偏差降至 17.33%，较零样本相对评估（51.66%）降低 34%；长度偏差降至 39.09%，显著低于基线。

        3. 领域通用性：在角色扮演、STEM、人文等领域，BSM 均能显著提升开源模型的一致性，降低偏差，部分领域（如 STEM）与 GPT-4 性能相当。

    - **约束文本生成任务**

        1. 约束满足：LLaMA-2-70B-chat+BSM 的 AP 达 28%，较零样本（22%）提升 6 个百分点，MC 降至 14.7%，较基线降低 12%。

        2. 故事质量：GPT-4 pairwise 评估中，BSM 生成的故事 93% 优于零样本基线，显著提升连贯性与可读性。

    - **消融与扩展性验证**

        1. 分支因子影响：分支因子为 4 时一致性最高，继续增加后性能饱和，位置偏差随分支因子增加持续降低。

        2. 评估尺度鲁棒性：1-5 分与 1-10 分评分尺度下，BSM 的一致性表现稳定，仅位置偏差略有波动。

        3. 无参考评估：在无 GPT-4 参考答案的推理任务中，BSM 仍优于零样本基线，验证其通用性。
