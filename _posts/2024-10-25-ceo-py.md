---
layout: post
toc: true
title: "CEO-Autonomous-Agent-Framework Document"
categories: Agent
tags: [AI, LLM, ceo-py, Agentic AI, Agent, AGI]
author:
  - vortezwohl
  - 吴子豪
---
<div align="center">
    <p>
        <img src="https://github.com/vortezwohl/CEO/releases/download/icon/ceo-icon-inv.png" alt="CEO" height="105">
    </p>
    <p style="font-weight: 200; font-size: 19px">
        An ultra-lightweight autonomous agent framework based on the <a href="https://arxiv.org/abs/2210.03629">ReAct</a> paradigm.
    </p>
    <p style="font-weight: 200; font-size: 19px">
        <a href="https://github.com/modelcontextprotocol">MCP</a> is currently supported. <a href="#integration-with-mcp">How to use McpAgent</a>.
    </p>
</div>

<h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/vortezwohl/CEO-Agentic-AI-Framework/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/vortezwohl/CEO-Agentic-AI-Framework/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/vortezwohl/CEO-Agentic-AI-Framework/blob/main/i18n/README_ja-jp.md">日本語</a>
    </p>
</h4>

<h5></br></h5>

## Abstract

This research proposes a lightweight autonomous agent framework based on the ReAct paradigm, designed to solve complex tasks through adaptive decision-making and multi-agent collaboration. Unlike traditional frameworks that rely on fixed workflows generated by an LLM-based scheduler, this framework dynamically generates next actions during agent execution based on prior trajectories, which enhances their robustness. To address potential termination issues caused by adaptive execution paths, I propose a timely abandonment strategy with a probabilistic penalty mechanism. For multi-agent collaboration, I introduce a memory transfer mechanism that enables shared and dynamically updated memory among agents. The framework's innovative timely abandonment strategy dynamically adjusts the probability of task abandonment via probabilistic penalties, allowing developers to balance conservative and exploratory tendencies in agent execution strategies by tuning hyperparameters. This significantly improves adaptability and task efficiency in complex environments. Additionally, agents can be expanded through external tool use, supported by modular design and MCP protocol compatibility for flexible action space expansion. Through explicit division of labor, the multi-agent collaboration mechanism enables agents to focus on specific task components, thereby significantly improving execution efficiency and quality.

## Experiments

The experimental results demonstrate that the `ceo-py` framework significantly outperforms `autogen` and `langchain` in handling tasks of varying complexity, especially in multi-step tasks with possible failures.

| Framework   | Version | Model                                      | one-step-task | multi-step-task | multi-step-task-with-possible-failure |
| ------ | --- |----------------------------------------- | ------------- | --------------- | ---------------------------------------- |
| `ceo-py` | `0.12.3rc0` |gpt-4o-mini<br>qwen-plus<br>deepseek-v3 | 96.7%</br>100%</br>100% | 100%</br>96.7%</br>100% | 76.7%</br>93.3%</br>93.3% |
| `autogen` | `0.4.9.2` |gpt-4o-mini<br>qwen-plus<br>deepseek-v3 |90%</br>90%</br>N/A | 53.3%</br>0%</br>N/A | 3.3%</br>3.3%</br>N/A |
| `langchain` | `0.3.21` |gpt-4o-mini<br>qwen-plus<br>deepseek-v3 | 73.3%</br>73.3%</br>76.7% | 13.3%</br>13.3%</br>13.3% | 10%</br>13.3%</br>6.7% |

- `one-step-task`: Tasks that can be completed with a single tool call.
- `multi-step-task`: Tasks that require multiple tool calls to complete, with no possibility of tool failure.
- `multi-step-task-with-possible-failure`: Tasks that require multiple tool calls to complete, where tools may fail, requiring the agent to retry and correct errors.

> The deepseek-v3 model is not supported by `autogen-agentchat==0.4.9.2`.

> You can reproduce my experiments [here](https://github.com/vortezwohl/ceo-experiment).

## Citation

If you are incorporating the `CEO` framework into your research, please remember to properly **cite** it to acknowledge its contribution to your work.

Если вы интегрируете фреймворк `CEO` в своё исследование, пожалуйста, не забудьте правильно сослаться на него, указывая его вклад в вашу работу.

もしあなたが研究に `CEO` フレームワークを組み入れているなら、その貢献を認めるために適切に引用することを忘れないでください.

如果您正在將 `CEO` 框架整合到您的研究中，請務必正確引用它，以聲明它對您工作的貢獻.

```latex
@software{Wu_CEO-Autonomous-Agent-Framework_2024,
author = {Wu, Zihao},
license = {GPL-3.0},
month = oct,
title = {{CEO-Autonomous-Agent-Framework}},
url = {https://github.com/vortezwohl/CEO-Autonomous-Agent-Framework},
version = {0.13.1},
year = {2024}
}
```

## Installation

- From [PYPI](https://pypi.org/project/ceo-py/)

    ```shell
    pip install ceo-py
    ```

- From [Github](https://github.com/vortezwohl/CEO/releases)

    Get access to unreleased features.

    ```shell
    pip install git+https://github.com/vortezwohl/CEO-Agentic-AI-Framework.git
    ```

## Quick Start

To start building your own agent, follow the steps listed.

1. set environmental variable `OPENAI_API_KEY`

    ```
    # .env
    OPENAI_API_KEY=sk-...
    ```

2. import required dependencies

    - `Agent` lets you instantiate an agent.

    - `Personality` is an enumeration class used for customizing personalities of agents.

        - `Personality.PRUDENT` makes the agent's behavior more cautious.

        - `Personality.INQUISITIVE` encourages the agent to be more proactive in trying and exploring.

    - `get_openai_model` gives you a `BaseChatModel` as thought engine.

    - `@ability(brain: BaseChatModel, cache: bool = True, cache_dir: str = '')` is a decorator which lets you declare a function as an `Ability`.

    - `@agentic(agent: Agent)` is a decorator which lets you declare a function as an `AgenticAbility`.

    ```python
    from ceo import (
        Agent,
        Personality,
        get_openai_model,
        ability,
        agentic
    )
    ```

3. declare functions as basic abilities

    ```python
    @ability
    def calculator(expr: str) -> float:
        # this function only accepts a single math expression
        return simplify(expr)

    @ability
    def write_file(filename: str, content: str) -> str:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
        return f'{content} written to {filename}.'
    ```

4. instantiate an agent

    You can grant abilities to agents while instantiating them.

    ```python
    model = get_openai_model()
    agent = Agent(abilities=[calculator, write_file], brain=model, name='CEO', personality=Personality.INQUISITIVE)
    ```

    - You can also grant more abilities to agents later:

        ```python
        agent.grant_ability(calculator)
        ```

        or

        ```python
        agent.grant_abilities([calculator])
        ```

    - To deprive abilities:

        ```python
        agent.deprive_ability(calculator)
        ```

        or

        ```python
        agent.deprive_abilities([calculator])
        ```
    
    You can change an agent's personality using method `change_personality(personality: Personality)`

    ```python
    agent.change_personality(Personality.PRUDENT)
    ```

5. assign a request to your agent

    ```python
    agent.assign("Here is a sphere with radius of 9.5 cm and pi here is 3.14159, find the area and volume respectively then write the results into a file called 'result.txt'.")
    ```

6. leave the rest to your agent

    ```python
    response = agent.just_do_it()
    print(response)
    ```

> `ceo` also supports multi-agent collaboration scenario, declare a function as agent calling ability with `@agentic(agent: Agent)`, then grant it to an agent. [See example](#multi-agent).

## Integration with [MCP](https://github.com/modelcontextprotocol)

I provide `McpAgent` to support tool calls based on the MCP protocol. Below is a brief guide to integrating `McpAgent` with `mcp.stdio_client`:

1. import required dependencies

    - `McpAgent` allows you to instantiate an agent capable of accessing MCP tools.

    - `StdioMcpConfig` is an alias for `mcp.client.stdio.StdioServerParameters` and serves as the MCP server connection configuration.

    - `@mcp_session(mcp_config: StdioMcpConfig)` allows you to declare a function as an MCP session.

    - `sync_call` allows you to synchronizedly call a coroutine function.

    ```python
    from ceo import (
        McpAgent,
        get_openai_model,
        StdioMcpConfig,
        mcp_session,
        sync_call
    )
    ```

2. create an MCP session

    - To connect with a stdio based MCP server, use `StdioMcpConfig`.

        ```python
        mcp_config = StdioMcpConfig(
            command='python',
            args=['./my_stdio_mcp_server.py'],
            env=dict(),
            cwd='./mcp_servers'
        )
        ```

        > A function decorated with `@mcp_session` will receive an MCP session instance as its first parameter. A function can be decorated with multiple `@mcp_session` decorators to access sessions for different MCP servers.

        ```python
        @sync_call
        @mcp_session(mcp_config)
        async def run(session, request: str) -> str:
            ...
        ```

    - To connect via HTTP with a SSE based MCP server, just provide the URL.

        ```python
        @sync_call
        @mcp_session('http://localhost:8000/sse')
        async def run(session, request: str) -> str:
            ...
        ```
    
    - To connect via websocket with a WS based MCP server, provide the URL.

        ```python
        @sync_call
        @mcp_session('ws://localhost:8000/message')
        async def run(session, request: str) -> str:
            ...
        ```


3. create an `McpAgent` instance within the MCP session

    After creating `McpAgent`, you need to call the `fetch_abilities()` method to retrieve tool configurations from the MCP server.

    ```python
    @sync_call
    @mcp_session(mcp_config)
    async def run(session, request: str) -> str:
        mcp_agent = await McpAgent(session=session, brain=model).fetch_abilities()
        ...
    ```

4. assign tasks to the `McpAgent` instance and await execution result

    ```python
    @sync_call
    @mcp_session(mcp_config)
    async def run(session, request: str) -> str:
        mcp_agent = await McpAgent(session=session, brain=model).fetch_abilities()
        result = await mcp_agent.assign(request).just_do_it()
        return result.conclusion
    ```

5. call the function

    ```python
    if __name__ == '__main__':
        ret = run(request='What can you do?')
        print(ret)
    ```

> I also provide the complete MCP agent test script. [See example](#mcp-agent).

## Observability

To make the working process of agents observable, I provide two hooks, namely `BeforeActionTaken` and `AfterActionTaken`. 
They allow you to observe and intervene in the decision-making and execution results of each step of the agent's actions. 
You can obtain and modify the agent's decision results for the next action through the `BeforeActionTaken` hook, 
while `AfterActionTaken` allows you to obtain and modify the execution results of the actions (the tampered execution results will be part of the agent's memory).

To start using hooks, follow the steps listed.

1. bring in hooks and messages from `CEO`

    ```python
    from ceo.brain.hook import BeforeActionTaken, AfterActionTaken
    from ceo.message import BeforeActionTakenMessage, AfterActionTakenMessage
    ```

2. declare functions and encapsulate them as hooks

    ```python
    def before_action_taken(agent: Agent, message: BeforeActionTakenMessage):
        print(f'Agent: {agent.name}, Next move: {message}')
        return message

    def after_action_taken(agent: Agent, message: AfterActionTakenMessage):
        print(f'Agent: {agent.name}, Action taken: {message}')
        return message

    before_action_taken_hook = BeforeActionTaken(before_action_taken)
    after_action_taken_hook = AfterActionTaken(after_action_taken)
    ```

    > In these two hook functions, you intercepted the message and printed the information in the message. 
    Afterwards, you returned the message unaltered to the agent. 
    Of course, you also have the option to **modify** the information in the message, 
    thereby achieving intervention in the agent's working process.

3. use hooks during the agent's working process

    ```python
    agent.assign(...).just_do_it(before_action_taken_hook, after_action_taken_hook)
    ```

## Examples

- ### Compound Tasks

    1. Find the surface area and volume of a sphere and write the results into a file.

        ```python
        from ceo import (
            Agent,
            Personality,
            get_openai_model,
            ability
        )
        from ceo.brain.hook import BeforeActionTaken, AfterActionTaken
        from ceo.message import BeforeActionTakenMessage, AfterActionTakenMessage
        from sympy import simplify
        from dotenv import load_dotenv

        load_dotenv()


        @ability
        def calculator(expr: str) -> float:
            # this function only accepts a single math expression
            return simplify(expr)


        @ability
        def write_file(filename: str, content: str) -> str:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(content)
            return f'{content} written to {filename}.'


        def before_action_taken(agent: Agent, message: BeforeActionTakenMessage):
            print(f'Agent: {agent.name}, Next move: {message}')
            return message


        def after_action_taken(agent: Agent, message: AfterActionTakenMessage):
            print(f'Agent: {agent.name}, Action taken: {message}')
            return message


        if __name__ == '__main__':
            ceo = Agent(abilities=[calculator, write_file], brain=get_openai_model(), name='CEO', personality=Personality.INQUISITIVE)
            radius = '(10.01 * 10.36 * 3.33 / 2 * 16)'  # 2762.663904
            pi = 3.14159
            output_file = 'result.txt'
            request = f"Here is a sphere with radius of {radius} cm and pi here is {pi}, find the area and volume respectively then write the results into a file called '{output_file}'."
            result = ceo.assign(request).just_do_it(BeforeActionTaken(before_action_taken), AfterActionTaken(after_action_taken))  # area = 95910378.2949379, volume = 88322713378.13666
            print(f'Result: {result}')
        ```

        ```
        # result.txt
        Surface Area: 95910378.2949379 cm²
        Volume: 88322713378.1367 cm³
        ```

        ```
        # stdout
        Agent: CEO, Next move: BeforeActionTakenMessage(ability={"ability_name": "calculator", "description": {"brief_description": "The `calculator` function evaluates a mathematical expression provided as a string and returns the simplified result as a float. It is designed to accept a single math expression, ensuring that the input is a valid string representation of a mathematical operation."}, "parameters_required": ["expr"], "returns": "<class 'float'>"}, arguments={'expr': '(10.01 * 10.36 * 3.33 / 2 * 16)'})
        Agent: CEO, Action taken: AfterActionTakenMessage(ability='calculator', arguments={'expr': '(10.01 * 10.36 * 3.33 / 2 * 16)'}, returns='2762.66390400000', summarization="I used the calculator ability to evaluate the expression '(10.01 * 10.36 * 3.33 / 2 * 16)', and the result is 2762.66390400000, which indicates the simplified result of the mathematical operation.")
        Agent: CEO, Next move: BeforeActionTakenMessage(ability={"ability_name": "calculator", "description": {"brief_description": "The `calculator` function evaluates a mathematical expression provided as a string and returns the simplified result as a float. It is designed to accept a single math expression, ensuring that the input is a valid string representation of a mathematical operation."}, "parameters_required": ["expr"], "returns": "<class 'float'>"}, arguments={'expr': '4 * 3.14159 * (2762.66390400000^2)'})
        Agent: CEO, Action taken: AfterActionTakenMessage(ability='calculator', arguments={'expr': '4 * 3.14159 * (2762.66390400000^2)'}, returns='95910378.2949379', summarization="I used the calculator ability to evaluate the expression '4 * 3.14159 * (2762.66390400000^2)', and the result is 95910378.2949379, which represents the simplified calculation of the given mathematical operation.")
        Agent: CEO, Next move: BeforeActionTakenMessage(ability={"ability_name": "calculator", "description": {"brief_description": "The `calculator` function evaluates a mathematical expression provided as a string and returns the simplified result as a float. It is designed to accept a single math expression, ensuring that the input is a valid string representation of a mathematical operation."}, "parameters_required": ["expr"], "returns": "<class 'float'>"}, arguments={'expr': '(4/3) * 3.14159 * (2762.66390400000^3)'})
        Agent: CEO, Action taken: AfterActionTakenMessage(ability='calculator', arguments={'expr': '(4/3) * 3.14159 * (2762.66390400000^3)'}, returns='88322713378.1367', summarization="I used the calculator ability to evaluate the expression '(4/3) * 3.14159 * (2762.66390400000^3)', and the result is 88322713378.1367, which represents the simplified value of the mathematical operation.")
        Agent: CEO, Next move: BeforeActionTakenMessage(ability={"ability_name": "write_file", "description": {"brief_description": "The `write_file` function writes the specified content to a file with the given filename. It takes two parameters: `filename`, which is the name of the file to be created or overwritten, and `content`, which is the string data to be written into the file. Upon successful writing, it returns a confirmation message indicating that the content has been written to the specified file."}, "parameters_required": ["filename", "content"], "returns": "<class 'str'>"}, arguments={'filename': 'result.txt', 'content': 'Surface Area: 95910378.2949379 cm²\nVolume: 88322713378.1367 cm³'})
        Agent: CEO, Action taken: AfterActionTakenMessage(ability='write_file', arguments={'filename': 'result.txt', 'content': 'Surface Area: 95910378.2949379 cm²\nVolume: 88322713378.1367 cm³'}, returns='Surface Area: 95910378.2949379 cm²\nVolume: 88322713378.1367 cm³ written to result.txt.', summarization="I used the write_file ability to write the specified content about surface area and volume to a file named 'result.txt'. The result confirms that the content was successfully written to the file.")
        Result: AllDoneMessage(success=True, conclusion="Your request has been fully achieved. The calculations resulted in a surface area of 95910378.2949379 cm² and a volume of 88322713378.1367 cm³, which were successfully written to 'result.txt'.", raw_response="--THOUGHT-PROCESS--  \n(Start) [Calculate radius]: I evaluated the expression '(10.01 * 10.36 * 3.33 / 2 * 16)' and obtained the radius as 2762.66390400000 cm. (--SUCCESS--)  \n(After: Calculate radius) [Calculate surface area]: I evaluated the expression '4 * 3.14159 * (2762.66390400000^2)' and obtained the surface area as 95910378.2949379 cm². (--SUCCESS--)  \n(After: Calculate surface area) [Calculate volume]: I evaluated the expression '(4/3) * 3.14159 * (2762.66390400000^3)' and obtained the volume as 88322713378.1367 cm³. (--SUCCESS--)  \n(After: Calculate volume) [Write results to file]: I wrote the surface area and volume to 'result.txt'. The content was successfully written. (--SUCCESS--)  \n\nBased on above assessments, here is my conclusion:  \n--CONCLUSION--  \nYour request has been fully achieved. The calculations resulted in a surface area of 95910378.2949379 cm² and a volume of 88322713378.1367 cm³, which were successfully written to 'result.txt'.  \n--END--", time_used=62.49354759999551, step_count=4)
        ```

- ### Multi-agent
    
    1. Ask the suitable agents to find the surface area and volume of a sphere and write the results into a file.
  
        ```python
        from sympy import simplify
        from dotenv import load_dotenv
        from ceo import (
            Agent,
            Personality,
            get_openai_model,
            agentic,
            ability
        )
        from ceo.brain.hook import BeforeActionTaken, AfterActionTaken
        from ceo.message import BeforeActionTakenMessage, AfterActionTakenMessage

        load_dotenv()
        model = get_openai_model()


        @ability(model)
        def calculator(expr: str) -> float:
            # this function only accepts a single math expression
            return simplify(expr)


        @ability(model)
        def write_file(filename: str, content: str) -> str:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(content)
            return f'{content} written to {filename}.'


        jack = Agent(abilities=[calculator], brain=model, name='Jack', personality=Personality.INQUISITIVE)
        tylor = Agent(abilities=[write_file], brain=model, name='Tylor', personality=Personality.PRUDENT)


        @agentic(jack)
        def agent1():
            return


        @agentic(tylor)
        def agent2():
            return


        def before_action_taken(agent: Agent, message: BeforeActionTakenMessage):
            print(f'Agent: {agent.name}, Next move: {message}')
            return message


        def after_action_taken(agent: Agent, message: AfterActionTakenMessage):
            print(f'Agent: {agent.name}, Action taken: {message}')
            return message


        if __name__ == '__main__':
            ceo = Agent(abilities=[agent1, agent2], brain=model, name='CEO', personality=Personality.INQUISITIVE)
            radius = '(10.01 * 10.36 * 3.33 / 2 * 16)'  # 2762.663904
            pi = 3.14159
            output_file = 'result.txt'
            request = f"Here is a sphere with radius of {radius} cm and pi here is {pi}, find the area and volume respectively then write the results into a file called '{output_file}'."
            result = ceo.assign(request).just_do_it(BeforeActionTaken(before_action_taken), AfterActionTaken(after_action_taken))  # area = 95910378.2949379, volume = 88322713378.13666
            print(f'Result: {result}')
        ```

        > In multi-agent collaboration scenario, you can assign different personalities to each distinct agent. For example, in the aforementioned script, Jack's capability is to perform calculations. I want him to try more and explore more, so Jack's personality is set to `Personality.INQUISITIVE`. On the other hand, Taylor's capability is to create and write files. For operations involving interaction with the external file system, I want him to be more cautious, so Taylor's personality is set to `Personality.PRUDENT`.

        ```
        # result.txt
        Surface Area: 95910378.2949379 cm²
        Volume: 88322713378.1367 cm³
        ```

        ```
        # stdout
        Agent: CEO, Next move: BeforeActionTakenMessage(ability={"ability_name": "__AgenticAbility__talk_to_Jack", "description": {"brief_description": "Initiates a conversation with \"Jack\" to use its abilities.", "detailed_description": "First, carefully consider and explore Jack's potential abilities in solving your tasks, then, if you need Jack's help, you must tell comprehensively, precisely and exactly what you need Jack to do.", "self_introduction_from_Jack": "My name is Jack. What can I do: I can evaluate mathematical expressions as a calculator and provide the result as a float. Additionally, I have the ability to retrieve my personal information, but this can only be done once.", "hint": "By reading <self_introduction_from_Jack>, you can learn what Jack can do, and then decide whether to initiates a conversation with Jack according to its abilities."}, "parameters_required": [], "returns": "<class 'str'>"}, arguments={'expression': '(10.01 * 10.36 * 3.33 / 2 * 16)'})
        Agent: Jack, Next move: BeforeActionTakenMessage(ability={"ability_name": "calculator", "description": {"brief_description": "The `calculator` function evaluates a mathematical expression provided as a string and returns the result as a float. It uses the `simplify` function to process the expression and ensure it is correctly computed."}, "parameters_required": ["expr"], "returns": "<class 'float'>"}, arguments={'expr': '(10.01 * 10.36 * 3.33 / 2 * 16)'})
        Agent: Jack, Action taken: AfterActionTakenMessage(ability='calculator', arguments={'expr': '(10.01 * 10.36 * 3.33 / 2 * 16)'}, returns='2762.66390400000', summarization="I used the calculator ability to evaluate the expression '(10.01 * 10.36 * 3.33 / 2 * 16)', and the result is '2762.66390400000', which indicates the computed value of the mathematical expression.")
        Agent: Jack, Next move: BeforeActionTakenMessage(ability={"ability_name": "calculator", "description": {"brief_description": "The `calculator` function evaluates a mathematical expression provided as a string and returns the result as a float. It uses the `simplify` function to process the expression and ensure it is correctly computed."}, "parameters_required": ["expr"], "returns": "<class 'float'>"}, arguments={'expr': '4 * 3.14159 * (2762.66390400000^2)'})
        Agent: Jack, Action taken: AfterActionTakenMessage(ability='calculator', arguments={'expr': '4 * 3.14159 * (2762.66390400000^2)'}, returns='95910378.2949379', summarization="I used the calculator ability to evaluate the expression '4 * 3.14159 * (2762.66390400000^2)', resulting in the value '95910378.2949379'.")
        Agent: Jack, Next move: BeforeActionTakenMessage(ability={"ability_name": "calculator", "description": {"brief_description": "The `calculator` function evaluates a mathematical expression provided as a string and returns the result as a float. It uses the `simplify` function to process the expression and ensure it is correctly computed."}, "parameters_required": ["expr"], "returns": "<class 'float'>"}, arguments={'expr': '(4/3) * 3.14159 * (2762.66390400000^3)'})
        Agent: Jack, Action taken: AfterActionTakenMessage(ability='calculator', arguments={'expr': '(4/3) * 3.14159 * (2762.66390400000^3)'}, returns='88322713378.1367', summarization="I used the calculator ability to evaluate the expression '(4/3) * 3.14159 * (2762.66390400000^3)', and the result is 88322713378.1367, which represents the computed volume of a sphere with a radius of approximately 2762.66.")
        Agent: CEO, Action taken: AfterActionTakenMessage(ability='__AgenticAbility__talk_to_Jack', arguments={'arguments': 'Ask for a favor.'}, returns='{"success": false, "response": "--THOUGHT-PROCESS--  \\n(Initial calculation) [Calculate radius]: I calculated the radius as \'2762.66390400000\' cm. (--SUCCESS--)  \\n(After: Calculate radius) [Calculate surface area]: I calculated the surface area using the formula \'4 * 3.14159 * (2762.66390400000^2)\', resulting in \'95910378.2949379\'. (--SUCCESS--)  \\n(After: Calculate surface area) [Calculate volume]: I calculated the volume using the formula \'(4/3) * 3.14159 * (2762.66390400000^3)\', resulting in \'88322713378.1367\'. (--SUCCESS--)  \\n(After: Calculate volume) [Write results to file]: There is no record in <history> indicating that the results were written to \'result.txt\'. (--FAILED--)  \\n\\nBased on above assessments, here is my conclusion:  \\n--CONCLUSION--  \\nYour request has not been fully achieved. I calculated the radius as \'2762.66390400000\' cm, the surface area as \'95910378.2949379\', and the volume as \'88322713378.1367\', but the results were not written to \'result.txt\'.  \\n--END--"}', summarization="I used the __AgenticAbility__talk_to_Jack ability to ask Jack for a favor. Jack calculated the radius, surface area, and volume of a sphere, but failed to write the results to 'result.txt'.")
        Agent: CEO, Next move: BeforeActionTakenMessage(ability={"ability_name": "__AgenticAbility__talk_to_Tylor", "description": {"brief_description": "Initiates a conversation with \"Tylor\" to use its abilities.", "detailed_description": "First, carefully consider and explore Tylor's potential abilities in solving your tasks, then, if you need Tylor's help, you must tell comprehensively, precisely and exactly what you need Tylor to do.", "self_introduction_from_Tylor": "My name is Tylor. What can I do: I can write content to a file and provide my personal information upon request, but the latter can only be used once.", "hint": "By reading <self_introduction_from_Tylor>, you can learn what Tylor can do, and then decide whether to initiates a conversation with Tylor according to its abilities."}, "parameters_required": [], "returns": "<class 'str'>"}, arguments={'file_name': 'result.txt', 'content': 'Surface Area: 95910378.2949379 cm²\nVolume: 88322713378.1367 cm³'})
        Agent: Tylor, Next move: BeforeActionTakenMessage(ability={"ability_name": "write_file", "description": {"brief_description": "The `write_file` function writes the specified content to a file with the given filename. It opens the file in write mode, encodes the content in UTF-8, and returns a confirmation message indicating that the content has been successfully written to the file."}, "parameters_required": ["filename", "content"], "returns": "<class 'str'>"}, arguments={'filename': 'result.txt', 'content': 'Surface Area: 95910378.2949379 cm²\nVolume: 88322713378.1367 cm³'})
        Agent: Tylor, Action taken: AfterActionTakenMessage(ability='write_file', arguments={'filename': 'result.txt', 'content': 'Surface Area: 95910378.2949379 cm²\nVolume: 88322713378.1367 cm³'}, returns='Surface Area: 95910378.2949379 cm²\nVolume: 88322713378.1367 cm³ written to result.txt.', summarization="I used the write_file ability to write the specified content about surface area and volume to a file named 'result.txt'. The result confirms that the content was successfully written to the file.")
        Agent: CEO, Action taken: AfterActionTakenMessage(ability='__AgenticAbility__talk_to_Tylor', arguments={'arguments': 'Ask for a favor.'}, returns='{"success": true, "response": "--THOUGHT-PROCESS--  \\n(Initial calculation) [Calculate radius]: The radius was calculated as \'2762.66390400000\' cm. (--SUCCESS--)  \\n(After: Calculate radius) [Calculate surface area]: The surface area was calculated using the formula \'4 * 3.14159 * (2762.66390400000^2)\', resulting in \'95910378.2949379\'. (--SUCCESS--)  \\n(After: Calculate surface area) [Calculate volume]: The volume was calculated using the formula \'(4/3) * 3.14159 * (2762.66390400000^3)\', resulting in \'88322713378.1367\'. (--SUCCESS--)  \\n(After: Calculate volume) [Write results to file]: The results were successfully written to \'result.txt\'. (--SUCCESS--)  \\n\\nBased on above assessments, here is my conclusion:  \\n--CONCLUSION--  \\nYour request has been fully achieved. The radius was calculated as \'2762.66390400000\' cm, the surface area as \'95910378.2949379\' cm², and the volume as \'88322713378.1367\' cm³. The results were successfully written to \'result.txt\'.  \\n--END--  "}', summarization="I used the __AgenticAbility__talk_to_Tylor ability to ask Tylor for a favor, which involved calculating the radius, surface area, and volume of a sphere. The results were successfully computed and written to 'result.txt'.")
        Result: AllDoneMessage(success=True, conclusion="Your request has been fully achieved. The radius was calculated as '2762.66390400000' cm, the surface area as '95910378.2949379' cm², and the volume as '88322713378.1367' cm³. The results were successfully written to 'result.txt'.", raw_response="--THOUGHT-PROCESS--  \n(Initial calculation) [Calculate radius]: The radius was calculated as '2762.66390400000' cm. (--SUCCESS--)  \n(After: Calculate radius) [Calculate surface area]: The surface area was calculated using the formula '4 * 3.14159 * (2762.66390400000^2)', resulting in '95910378.2949379' cm². (--SUCCESS--)  \n(After: Calculate surface area) [Calculate volume]: The volume was calculated using the formula '(4/3) * 3.14159 * (2762.66390400000^3)', resulting in '88322713378.1367' cm³. (--SUCCESS--)  \n(After: Calculate volume) [Write results to file]: The results were successfully written to 'result.txt'. (--SUCCESS--)  \n\nBased on above assessments, here is my conclusion:  \n--CONCLUSION--  \nYour request has been fully achieved. The radius was calculated as '2762.66390400000' cm, the surface area as '95910378.2949379' cm², and the volume as '88322713378.1367' cm³. The results were successfully written to 'result.txt'.  \n--END--  ", time_used=123.79718699998921, step_count=2)
        ```

- ### MCP Agent

    1. Ask a browser-use augmented mcp agent to search for and find out what RL is.

        ```python
        from ceo import (
            McpAgent,
            get_openai_model,
            ability,
            sync_call,
            StdioMcpConfig,
            __BLOG__
        )
        from ceo.util.mcp_session import mcp_session
        from ceo.brain.hook import BeforeActionTaken, AfterActionTaken
        from ceo.message import BeforeActionTakenMessage, AfterActionTakenMessage
        from dotenv import load_dotenv

        load_dotenv()
        model = get_openai_model()
        stdio_mcp_config = StdioMcpConfig(
            command='python',
            args=['./playwright-plus-python-mcp.py'],
            env=dict(),
            cwd='./mcp_server'
        )


        @ability(model)
        def write_file(filename: str, content: str) -> str:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(content)
            return f'{content} written to {filename}.'


        def before_action_taken(agent: McpAgent, message: BeforeActionTakenMessage):
            print(f'Agent: {agent.name}, Next move: {message.ability.name}')
            return message


        def after_action_taken(agent: McpAgent, message: AfterActionTakenMessage):
            print(f'Agent: {agent.name}, Action taken: {message.summarization}')
            return message


        @sync_call
        @mcp_session(stdio_mcp_config)
        async def run(session, request: str) -> str:
            mcp_agent = await McpAgent(session=session, brain=model).fetch_abilities()
            mcp_agent.grant_ability(write_file)
            result = await mcp_agent.assign(request).just_do_it(
                BeforeActionTaken(before_action_taken),
                AfterActionTaken(after_action_taken)
            )
            return result.conclusion


        if __name__ == '__main__':
            output_file = 'result.txt'
            request = (f'What is reinforcement learning? Bing (www.bing.com) it and write down the search results into local file: {output_file}. '
                    f'Then navigate to {__BLOG__}.')
            ret = run(request)
            print(ret)

        ```

        ```
        # result.txt
        Reinforcement Learning: An Overview
        Reinforcement Learning (RL)
        Key Concepts of Reinforcement Learning
        Agent: The learner or decision-maker.
        Agent
        Environment: Everything the agent interacts with.
        Environment
        State: A specific situation in which the agent finds itself.
        State
        Action: All possible moves the agent can make.
        Action
        Reward: Feedback from the environment based on the action taken
        1.
        Reward
        How Reinforcement Learning Works
        IBM
        https://www.ibm.com › think › topics › reinforcement-learning
        What is reinforcement learning? | IBM
        2024年3月25日 · In reinforcement learning, an agent learns to make decisions by interacting with an environment. It is used in robotics and other decision-making settings. Reinforcement …
        2024年3月25日
        Wikipedia
        https://en.wikipedia.org › wiki › Reinforcement_learning
        Reinforcement learning - Wikipedia
        Overview
        Principles
        Exploration
        Algorithms for control learning
        Theory
        Research
        Comparison of key algorithms
        Statistical comparison of reinforcement learning algorithms
        machine learning
        optimal control
        intelligent agent
        take actions
        maximize a reward
        three basic machine learning paradigms
        supervised learning
        unsupervised learning
        Wikipedia · CC-BY-SA 许可下的文字
        · CC-BY-SA 许可下的文字
        CC-BY-SA 许可
        预计阅读时间：10 分钟
        其他用户还问了以下问题
        What are reinforcement learning algorithms?
        Reinforcement learning encompasses a variety of algorithms. Some of the most notable include: Q-learning is a model-free, value-based algorithm that learns an action-value function (Q-function) to estimate the expected cumulative reward for taking a given action in a given state.
        Q-learning
        What is reinforcement learning? - cudocompute.com
        cudocompute.com
        What is reinforcement learning (RL)?
        Reinforcement learning (RL) is a type of machine learning process that focuses on decision making by autonomous agents. An autonomous agent is any system that can make decisions and act in response to its environment independent of direct instruction by a human user. Robots and self-driving cars are examples of autonomous agents.
        ```

        ```
        # stdout
        Agent: 智能體47239e型號, Next move: playwright_navigate
        Agent: 智能體47239e型號, Action taken: I utilized the **playwright_navigate** ability to navigate to the URL "https://www.bing.com/search?q=What+is+reinforcement+learning". The result confirms that the navigation was successful, and the page content includes search results related to "reinforcement learning", such as articles from IBM, Wikipedia, and other sources. This operation successfully retrieved the desired webpage content for further processing or analysis.
        Agent: 智能體47239e型號, Next move: write_file
        Agent: 智能體47239e型號, Action taken: I used the `write_file` ability to write a detailed overview of Reinforcement Learning into a file named "result.txt". The content included key concepts such as Agent, Environment, State, Action, and Reward, along with additional information from sources like IBM and Wikipedia. The result confirms that the content was successfully written to the specified file.
        Agent: 智能體47239e型號, Next move: playwright_navigate
        Agent: 智能體47239e型號, Action taken: I used the playwright_navigate ability to navigate to the URL "https://vortezwohl.github.io". The result confirms that the navigation was successful, and the page content includes text such as "vortezwohl", "About", "Years", "Categories", "Tags", and various blog post titles related to reinforcement learning, machine learning concepts, and other technical topics.
        Your request has been fully achieved. I searched for "What is reinforcement learning" on Bing, retrieved relevant information, and wrote it into a file named "result.txt". Subsequently, I navigated to the website "https://vortezwohl.github.io", confirming that the navigation was successful and the page content was as expected.
        ```