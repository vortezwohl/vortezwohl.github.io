---
layout: post
toc: true
title: "技术调研 GROVE 框架: A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence"
categories: NLP
tags: [NLP]
author:
  - vortezwohl
  - 吴子豪
---
现有条件故事生成（尤其是复杂情节生成）领域存在以下核心问题和挑战：**1.** 基于大语言模型（LLMs）的方法虽能生成流畅、符合指令的故事，但难以平衡情节复杂性与创造性。若通过详细提示强制控制情节，会限制故事的创造性；若提示过于简单，又无法生成复杂情节; **2.** 现有研究多聚焦于提升可控性（如遵循结局、角色设定）和逻辑连贯性（如融入常识知识），但很少专门探索如何生成复杂情节。例如，基于 BART 或 GPT-2 的模型主要优化对细粒度指令的遵循，而常识知识融入方法侧重合理性，均未针对 “情节复杂性” 设计机制; **3.** 现有 LLM 提示方法（如 ICL、CoT）多依赖手动选择的少样本示例，缺乏自动获取相关人类故事作为灵感的机制；且优化方式多为 “分步解构任务”（如先推理再生成），而非对完整故事进行迭代深化，难以挖掘深层背景信息; **4.** 生成的故事常存在逻辑断层（如角色动机不明、情节突兀），但现有方法缺乏系统性机制来识别并补充这些模糊点，导致故事可信度和丰富度不足; 而 **GROVE (检索增强证据森林故事生成) 框架**针对上述问题, 提出了一套解决方案, 主要解决了 3 个问题: **1.** 在不限制创造性的前提下，通过外部知识增强情节复杂性; **2.** 自动识别并补充故事中的模糊点，提升叙事可信度; **3.** 平衡 “遵循目标条件” 与 “拓展多元情节” 的矛盾;

Paper: [GROVE: A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence](https://doi.org/10.48550/arXiv.2310.05388)

## GROVE 核心架构

1. **检索库**

    收集人类撰写的故事，通过 LLM 自动提取每个故事的目标条件（如情绪、主题、情节）作为 “键”，故事文本作为 “值”，构建检索库。当给定新的生成任务时，通过语义相似度匹配，检索最相关的人类故事作为少样本示例，为 LLM 提供情节灵感。

2. **证据森林**

    1. 首先生成初始故事；

    2. 识别故事中的模糊点（如 “角色动机不明”“情节逻辑断层”）；

    3. 通过 “问为什么” 提示策略，迭代生成证据树：以模糊点为根节点，每层节点通过 “为什么这个模糊点合理” 的追问补充背景信息，最终形成由多棵证据树组成的 “证据森林”（每棵树对应一个模糊点，节点间为补充关系）。

3. **证据链整合与故事重写**

    从证据森林中筛选与目标条件最相关的证据链（从根节点到叶节点的路径），将其融入初始故事，补充背景信息，增强情节复杂性和可信度。

以上架构的创新点如下:

1. **检索增强的少样本学习**

    不同于手动选择示例，GROVE 通过检索库自动获取相关人类故事，让 LLM 学习多元情节模式，在保持创造性的同时提升复杂性.

2. **“问为什么” 的迭代证据生成**

    创新性地通过迭代追问构建证据森林，系统性补充故事模糊点，挖掘深层背景（如角色过往经历、事件因果），解决了现有方法 “重生成、轻深化” 的问题.

3. **证据链的选择性整合**

    从证据森林中筛选最优链并融入故事，避免信息冗余或冲突，同时保证与目标条件的相关性，平衡 “复杂性” 与 “可控性”.

## GROVE 的局限性也十分明显

1. **过于依赖基础模型能力**

    GROVE 的性能受限于所用 LLM 的固有能力，若 LLM 本身难以生成复杂情节，框架的优化效果会受限, 这导致该框架必须配合最先进的大型模型使用.

2. **潜在偏见与多样性问题**

    LLM 可能偏好某些证据链或叙事模式，导致生成故事的多样性下降；若检索库中存在偏见数据，可能进一步放大偏差.

3. **伦理与法律风险**

    检索库依赖人类故事，若数据来源处理不当可能涉及版权问题；恶意使用时，框架可能生成有害或偏见内容.

为了解决以上问题, 作者提出了后续研究方向:

1. **优化 LLM 依赖问题**: 探索不依赖单一 LLM 的混合架构，或设计针对故事生成的专用模型，减少对通用 LLM 能力的依赖.

2. **减轻偏见与提升多样性**: 研究更公平的证据链选择机制，或引入对抗训练减少 LLM 的偏好性.

3. **增强伦理与版权合规检查**: 开发自动检测和过滤有害内容的模块，探索基于版权许可的检索库构建方案.

4. **深化复杂情节建模**: 进一步研究 “情节复杂度” 的量化指标，设计更精细的证据生成策略.


