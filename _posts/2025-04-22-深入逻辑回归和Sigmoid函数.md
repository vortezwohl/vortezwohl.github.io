---
layout: post
toc: true
title: "深入逻辑回归模型"
categories: Math
tags: [Math, MachineLearning, DeepLearning]
author:
  - vortezwohl
  - 吴子豪
---
逻辑回归（Logistic Regression）是一种用于解决二分类问题的统计模型，在机器学习中应用广泛。其核心思想是通过寻找一个合适的决策边界，将不同类别数据分开。逻辑回归模型的假设函数是 sigmoid 函数。Sigmoid 函数的表达式是 $\sigma(z) = \frac{1}{1 + e^{-z}}$, 其中 $z$ 是逻辑回归的线性组合部分 (即 $z=\theta^T x$, $\theta$ 是模型参数, $x$ 是输入特征). 这个函数具有独特的 $S$ 型曲线特征, 其输出值的范围被限制在 $(0, 1)$. 当 $z$ 趋向正无穷时, $\sigma(z)$ 趋近于 1; 当 $z$ 趋向负无穷时, $\sigma(z)$ 趋近于 0; 当 $z=0$ 时, $\sigma(z) = 0.5$. 这种性质使得它能够将线性回归的输出映射为概率值, 从而实现对样本类别的估计.

## 二分类问题

二分类问题是监督学习中的一种常见任务，其目标是将样本分为两个互斥的类别。例如，判断肿瘤是否为恶性（是或否）。逻辑回归是一种常用的二分类，算法它通过学习样本的特征与类别之间的关系，预测新样本属于某一类别的概率。

## Sigmoid 函数

sigmoid 函数是一种常用的压缩函数, 其数学表达式为:

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

其中, $z$ 是函数的输入. sigmoid 函数的输出范围在 $(0, 1)$, 且具有平滑的 $S$ 形曲线特性. 在二分类问题中, sigmoid 函数将线性回归的输出结果压缩到 $(0, 1)$ 区间, 使其可以被解释为概率值.


### 对线性回归的压缩

逻辑回归模型通过线性回归模型得到一个线性组合 $z = \theta^x T$, 其中 $\theta$ 是模型参数, $x$ 是输入特征. 然后, 将 $z$ 作为 sigmoid 函数的输入, 得到输出 $h_\theta(x) = \sigma(z)$. 这个输出值表示样本属于正类的概率. 例如, 若 $h_\theta(x) \ge 0.5$, 则预测样本属于正类, 否则属于负类.

### 对数似然函数

逻辑回归算法常用的损失函数是交叉熵损失

...
